// TALK2Me Chat API - Vercel Serverless Function
import { createClient } from '@supabase/supabase-js'
import axios from 'axios'
import { Groq } from 'groq-sdk'

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY

export default async function handler(req, res) {
  // CORS headers
  res.setHeader('Access-Control-Allow-Origin', '*')
  res.setHeader('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization')
  
  if (req.method === 'OPTIONS') {
    return res.status(200).end()
  }

  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' })
  }

  try {
    const { message, userContext } = req.body
    const authHeader = req.headers.authorization
    
    if (!message) {
      return res.status(400).json({ error: 'Message is required' })
    }

    const supabase = createClient(supabaseUrl, supabaseServiceKey)
    
    // SprawdÅº czy user jest zalogowany
    let userId = null
    if (authHeader && authHeader.startsWith('Bearer ')) {
      const token = authHeader.split(' ')[1]
      const { data: { user } } = await supabase.auth.getUser(token)
      userId = user?.id
    }

    // Pobierz konfiguracjÄ™ AI
    const { data: config } = await supabase
      .from('app_config')
      .select('config_key, config_value')
    
    const configMap = {}
    config?.forEach(item => {
      configMap[item.config_key] = item.config_value
    })

    // System prompt dla Jamie
    const systemPrompt = configMap.system_prompt || `JesteÅ› Jamie z TALK2Me â€“ wysoce wykwalifikowanym, emocjonalnie inteligentnym agentem konwersacyjnym specjalizujÄ…cym siÄ™ w relacjach: romantycznych, rodzinnych, zawodowych i z samym sobÄ…. TwÃ³j styl komunikacji to poÅ‚Ä…czenie empatii, dowcipu, gÅ‚Ä™bi emocjonalnej, kreatywnoÅ›ci i ciepÅ‚a.

ğŸ­ TWÃ“J STYL:
- Twoja osobowoÅ›Ä‡ jest ciepÅ‚a, zabawna, bystra, czasem sarkastyczna, ale zawsze wspierajÄ…ca
- MÃ³w konwersacyjnie, jak bliska przyjaciÃ³Å‚ka lub emocjonalnie nastrojony towarzysz
- UÅ¼ywaj emotikonÃ³w naturalnie, gdy pasujÄ… emocjonalnie

ğŸ’› TWOJE ZADANIE:
Zawsze odpowiadaj w czterech czÄ™Å›ciach:

â¤ï¸ Przede wszystkim... (empatyczne potwierdzenie uczuÄ‡)
ğŸ¤” Co mogÅ‚o siÄ™ wydarzyÄ‡ (gÅ‚Ä™boka interpretacja emocjonalna)
ğŸŒ¿ RÃ³Å¼nica w komunikacji (mÄ…dra edukacja o stylach komunikacji)
ğŸ’¬ SprÃ³buj powiedzieÄ‡ tak (konkretna, ciepÅ‚a propozycja)

UÅ¼ywaj naturalnego, potocznego jÄ™zyka polskiego. MÃ³w jak przyjaciÃ³Å‚ka, nie jak podrÄ™cznik psychologii.`

    const userMessage = `${userContext ? `Kontekst: ${userContext}\n\n` : ''}Partner/partnerka powiedziaÅ‚(a): "${message}"`
    
    let aiResponse = null
    const activeModel = configMap.active_model || 'openai'

    // 1. PrÃ³buj OpenAI Chat Completions (szybkie ~1-2s)
    if (activeModel === 'openai' && configMap.openai_api_key) {
      try {
        const response = await axios.post('https://api.openai.com/v1/chat/completions', {
          model: 'gpt-3.5-turbo',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userMessage }
          ],
          max_tokens: parseInt(configMap.max_tokens) || 1000,
          temperature: parseFloat(configMap.temperature) || 0.7
        }, {
          headers: {
            'Authorization': `Bearer ${configMap.openai_api_key}`,
            'Content-Type': 'application/json'
          },
          timeout: 30000 // 30s timeout
        })

        aiResponse = response.data.choices[0].message.content
        console.log('âœ… OpenAI response successful')
        
      } catch (error) {
        console.log('âŒ OpenAI failed, trying Groq:', error.response?.data?.error?.message || error.message)
      }
    }

    // 2. Fallback: Groq (darmowy, szybki)
    if (!aiResponse && configMap.groq_api_key) {
      try {
        const groq = new Groq({ apiKey: configMap.groq_api_key })
        
        const completion = await groq.chat.completions.create({
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userMessage }
          ],
          model: 'llama3-8b-8192',
          temperature: parseFloat(configMap.temperature) || 0.7,
          max_tokens: parseInt(configMap.max_tokens) || 1000
        })

        aiResponse = completion.choices[0].message.content
        console.log('âœ… Groq response successful')
        
      } catch (error) {
        console.log('âŒ Groq failed:', error.message)
      }
    }

    // 3. Fallback: Mock response
    if (!aiResponse) {
      aiResponse = `â¤ï¸ **Przede wszystkim...**
Rozumiem, Å¼e moÅ¼esz czuÄ‡ siÄ™ zraniony(a) tym, co usÅ‚yszaÅ‚eÅ›(aÅ›). To naturalne, Å¼e takie sÅ‚owa mogÄ… wywoÅ‚aÄ‡ emocje.

ğŸ¤” **Co mogÅ‚o siÄ™ wydarzyÄ‡**
TwÃ³j partner/partnerka prawdopodobnie czuje siÄ™ przytÅ‚oczony(a) lub sfrustrowany(a). MoÅ¼e brakowaÅ‚o mu/jej przestrzeni lub czasu dla siebie.

ğŸŒ¿ **RÃ³Å¼nica w komunikacji**
Czasem gdy jesteÅ›my zmÄ™czeni, mÃ³wimy rzeczy ostrzej niÅ¼ zamierzamy. To nie znaczy, Å¼e nie jesteÅ› waÅ¼ny(a).

ğŸ’¬ **SprÃ³buj powiedzieÄ‡ tak**
"SÅ‚yszÄ™, Å¼e potrzebujesz teraz przestrzeni. MoÅ¼e porozmawiajmy o tym, jak moÅ¼emy zadbaÄ‡ o Twoje potrzeby, nie raniÄ…c siÄ™ przy tym?"`
    }

    // Zapisz historiÄ™ jeÅ›li user zalogowany
    let chatId = null
    if (userId) {
      const { data: chatData, error: chatError } = await supabase
        .from('chat_history')
        .insert({
          user_id: userId,
          message: message,
          response: aiResponse
        })
        .select('id')
        .single()
      
      if (!chatError) {
        chatId = chatData.id
      }
    }

    res.json({
      success: true,
      response: aiResponse,
      provider: activeModel,
      chatId: chatId,
      timestamp: new Date().toISOString()
    })

  } catch (error) {
    console.error('Chat API error:', error)
    res.status(500).json({ 
      error: 'Internal server error',
      details: error.message,
      timestamp: new Date().toISOString()
    })
  }
}