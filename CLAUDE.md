# TALK2Me - Stan Projektu & Historia

## üìã O Projekcie
**TALK2Me** - Aplikacja mobilna AI do pomocy w komunikacji w zwiƒÖzkach
- **W≈Ça≈õciciel**: Natalia Rybarczyk (Nat-thelifecreator)
- **Wsp√≥≈Çpracownik**: Maciej (narzeczony Natalii)
- **Repo GitHub**: https://github.com/Nat-thelifecreator/TALK2Me

## üöÄ AKTUALNE ≈öRODOWISKA (Stycze≈Ñ 2025)

### üî¥ PRODUKCJA (Railway) - G≈Å√ìWNE
- **URL**: https://talk2me.up.railway.app
- **Branch**: `railway-migration` ‚ö†Ô∏è (NIE main!)
- **Platforma**: Railway.app (Express.js server)
- **Deploy**: Auto-deploy przy ka≈ºdym push na `railway-migration`
- **Status**: ‚úÖ Dzia≈Ça, ale wymaga optymalizacji

### üü° BACKUP (Vercel) - STARE
- **URL**: https://tk2me.vercel.app
- **Branch**: `main`
- **Platforma**: Vercel (Serverless Functions)
- **Deploy**: Auto-deploy z main (obecnie nieu≈ºywane)
- **Status**: ‚úÖ Dzia≈Ça jako backup

## üéØ Aktualny Stan (Stycze≈Ñ 2025)
Projekt jest **~70% gotowy** - podstawowe funkcje dzia≈ÇajƒÖ, ale brakuje kluczowych element√≥w:

### ‚úÖ Co Dzia≈Ça
1. **Chat z AI** - streaming odpowiedzi w czasie rzeczywistym
2. **Autoryzacja** - logowanie/rejestracja u≈ºytkownik√≥w
3. **Admin Panel** - zarzƒÖdzanie konfiguracjƒÖ (/admin, has≈Ço: qwe123)
4. **Historia rozm√≥w** - zapisywanie czat√≥w w bazie
5. **Ulubione** - oznaczanie wa≈ºnych wiadomo≈õci
6. **Dwa ≈õrodowiska** - Railway (prod) + Vercel (backup)

### ‚ùå Czego Brakuje (30% projektu)
1. **System pamiƒôci AI** - personalizacja na podstawie historii u≈ºytkownika
2. **System konwersacji** - grupowanie czat√≥w w wƒÖtki (jak ChatGPT)
3. **Optymalizacja wydajno≈õci** - serwer "muli", brak cache'owania
4. **OAuth** - logowanie przez Google/Apple
5. **PWA** - instalacja jako aplikacja mobilna
6. **Testy jednostkowe** - zero coverage

### üîß Architektura Techniczna

#### RAILWAY (Produkcja):
- **Frontend**: Static files served by Express
- **Backend**: Express.js server (server.js)
- **Branch**: `railway-migration`
- **RAM**: 8GB (vs 1GB na Vercel)
- **Deploy**: Git push ‚Üí auto-deploy

#### VERCEL (Backup):
- **Frontend**: Static hosting
- **Backend**: Serverless Functions (/api/)
- **Branch**: `main`
- **RAM**: 1GB limit
- **Deploy**: Git push ‚Üí auto-deploy

#### WSP√ìLNE:
- **Baza danych**: Supabase (PostgreSQL)
- **AI Models**: OpenAI GPT-3.5-turbo, Groq Llama
- **Auth**: Custom JWT (nie Supabase Auth)

## üìÅ Struktura Projektu
```
/Users/nataliarybarczyk/TALK2Me/
‚îú‚îÄ‚îÄ server.js              # üÜï Express server dla Railway
‚îú‚îÄ‚îÄ railway.json           # üÜï Konfiguracja Railway
‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îú‚îÄ‚îÄ index.html         # G≈Ç√≥wna aplikacja 
‚îÇ   ‚îî‚îÄ‚îÄ admin.html         # Panel administratora
‚îú‚îÄ‚îÄ api/                   # Handlery (u≈ºywane przez oba ≈õrodowiska)
‚îÇ   ‚îú‚îÄ‚îÄ chat.js            # G≈Ç√≥wny endpoint AI chat
‚îÇ   ‚îú‚îÄ‚îÄ history.js         # Historia rozm√≥w
‚îÇ   ‚îú‚îÄ‚îÄ favorites.js       # Ulubione wiadomo≈õci
‚îÇ   ‚îú‚îÄ‚îÄ conversations.js   # üÜï System konwersacji (w budowie)
‚îÇ   ‚îî‚îÄ‚îÄ admin/config.js    # ZarzƒÖdzanie konfiguracjƒÖ
‚îú‚îÄ‚îÄ lib/                   # üîú Przysz≈Çe modu≈Çy
‚îÇ   ‚îî‚îÄ‚îÄ memory-manager.js  # (planowany) LangChain memory
‚îú‚îÄ‚îÄ archive/               # üÜï Stara dokumentacja
‚îÇ   ‚îú‚îÄ‚îÄ README_legacy.md
‚îÇ   ‚îî‚îÄ‚îÄ PROJECT_DOCUMENTATION_*.md
‚îú‚îÄ‚îÄ supabase-*.sql         # Schematy bazy danych
‚îú‚îÄ‚îÄ package.json           # Dependencies + scripts
‚îú‚îÄ‚îÄ vercel.json            # Konfiguracja Vercel (backup)
‚îî‚îÄ‚îÄ CLAUDE.md              # Ten plik (g≈Ç√≥wna dokumentacja)
```

## üóÉÔ∏è Supabase Database Schema
```sql
-- Tabele:
users (id, email, password, name, subscription_type, is_verified)
chat_history (id, user_id, message, response, ai_model, created_at)
app_config (id, config_key, config_value, updated_at)
```

## üîë Zmienne ≈örodowiskowe (Vercel)
```bash
NEXT_PUBLIC_SUPABASE_URL=https://hpxzhbubvdgxdvwxmhzo.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
```
**Uwaga**: Wszystkie inne konfiguracje (API keys, assistant ID, etc.) sƒÖ teraz przechowywane w bazie danych i zarzƒÖdzane przez panel admina.

## üöÄ Endpointy API
- `GET /api/setup` - Inicjalizacja bazy danych (‚úÖ dzia≈Ça)
- `POST /api/chat` - Chat z AI (‚úÖ Chat Completions + Streaming)
- `GET/POST /api/history` - Historia rozm√≥w u≈ºytkownika
- `GET/POST /api/favorites` - ZarzƒÖdzanie ulubionymi
- `GET/PUT /api/admin/config` - Panel admin (has≈Ço: qwe123)
- `POST /api/auth/login` - Logowanie u≈ºytkownika
- `POST /api/auth/register` - Rejestracja nowego u≈ºytkownika
- `GET /api/auth/me` - Pobieranie danych zalogowanego u≈ºytkownika

### ü§ñ Chat API Szczeg√≥≈Çy (/api/chat)
**Format zapytania**:
```json
POST /api/chat
{
  "message": "Partner powiedzia≈Ç: nie mam czasu na rozmowy",
  "userContext": "opcjonalny kontekst sytuacji"
}
```

**AI Logic Flow**:
1. **Primary**: OpenAI Chat Completions API (gpt-3.5-turbo)
2. **Fallback**: Groq API (llama3-8b-8192) 
3. **Streaming**: Server-Sent Events (SSE) dla p≈Çynnego wy≈õwietlania

**Response Format**: 
- Streaming chunks przez SSE
- Format: `data: {"content": "tekst"}\n\n`
- Zako≈Ñczenie: `data: [DONE]\n\n`
- Frontend wy≈õwietla tekst w czasie rzeczywistym

**Response Speed**: 
- OpenAI Chat Completions: ~1-2s (z streamingiem)
- Groq: ~2-3s (bez streamingu, fallback)
- Poprzednio Assistant API: ~10-30s ‚ùå

## ‚ö†Ô∏è KLUCZOWE INFORMACJE DLA DEVELOPER√ìW

### üî¥ GDZIE PRACUJEMY:
- **Branch**: `railway-migration` (NIE main!)
- **Deploy**: Railway z brancha `railway-migration`
- **URL produkcji**: https://talk2me.up.railway.app
- **Ka≈ºdy push** na `railway-migration` = auto-deploy

### üü° CO Z VERCEL:
- Branch `main` nadal dzia≈Ça na Vercel
- To tylko backup, NIE rozwijamy go
- URL: https://tk2me.vercel.app

### üîß JAK PRACOWAƒÜ:
```bash
# Zawsze sprawd≈∫ ≈ºe jeste≈õ na w≈Ça≈õciwym branchu!
git checkout railway-migration

# Twoje zmiany
git add .
git commit -m "opis"
git push origin railway-migration

# NIE pushuj do main!
```

## üõ†Ô∏è Ostatnie Zmiany & Fixes
1. **JavaScript Error Fix**: Naprawiony b≈ÇƒÖd w index.html:1891 (duplicate method)
2. **ES6 Modules**: Dodano "type": "module" do package.json
3. **Auto-deploy**: Skonfigurowany webhook GitHub ‚Üí Vercel
4. **Testing**: Testy auto-deploy z version bump v1.1 ‚Üí v1.3
5. **Assistant API Integration**: Usuniƒôty hardkodowany prompt, zaimplementowana integracja z OpenAI Assistant API
6. **Auth System Restored**: Przywr√≥cony system logowania/rejestracji z endpointami API
7. **Clean Assistant Messages**: Usuniƒôte formatowanie wiadomo≈õci u≈ºytkownika - teraz przesy≈Çana jest czysta wiadomo≈õƒá do Assistant API
8. **Removed 4-Section Format**: Usuniƒôte formatowanie odpowiedzi na 4 sekcje - aplikacja wy≈õwietla czystƒÖ odpowied≈∫ z Assistant API
9. **üöÄ CHAT COMPLETIONS + STREAMING**: Zamieniono wolne Assistant API na szybkie Chat Completions z SSE streamingiem (10x szybsze!)
10. **üìù Dokumentacja URL**: Zaktualizowano Supabase URL w dokumentacji na nowy projekt

## üìã W Trakcie Realizacji
### ‚úÖ FAZA 1 (UKO≈ÉCZONA):
- Chat Completions z streamingiem
- 10x szybsze odpowiedzi (1-2s vs 10-30s)
- P≈Çynne wy≈õwietlanie tekstu

### üöß FAZA 2 - System Konwersacji (3h):
#### 2.1 Utworzenie nowych tabel (30min):
```sql
-- Tabela konwersacji
CREATE TABLE conversations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES users(id),
  title TEXT,
  last_message_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT NOW()
);

-- Tabela wiadomo≈õci
CREATE TABLE messages (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  conversation_id UUID NOT NULL REFERENCES conversations(id),
  user_id UUID NOT NULL REFERENCES users(id),
  role TEXT CHECK (role IN ('user', 'assistant', 'function', 'system')) NOT NULL,
  content TEXT NOT NULL,
  created_at TIMESTAMP DEFAULT NOW()
);

-- Indeksy
CREATE INDEX idx_messages_conversation ON messages(conversation_id, created_at);
CREATE INDEX idx_conversations_user ON conversations(user_id, last_message_at DESC);
```

#### 2.2 Migracja danych (1h):
- Backup tabeli chat_history
- Grupowanie wiadomo≈õci po datach
- Utworzenie konwersacji dla ka≈ºdego dnia
- Przeniesienie par message/response do messages

#### 2.3 API Endpoints (1h):
- `GET /api/conversations` - lista konwersacji
- `POST /api/conversations` - nowa konwersacja
- `GET /api/conversations/:id/messages` - wiadomo≈õci
- `PUT /api/conversations/:id/title` - zmiana tytu≈Çu
- `DELETE /api/conversations/:id` - usuwanie

#### 2.4 Update chat.js (30min):
- Obs≈Çuga conversationId w request
- Auto-tworzenie konwersacji
- Update last_message_at

### üìÖ FAZA 3 - System Pamiƒôci z pgvector (4h):
#### 3.1 Setup pgvector (30min):
```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

#### 3.2 Tabela memories (45min):
```sql
CREATE TABLE memories (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES users(id),
  conversation_id UUID REFERENCES conversations(id),
  summary TEXT NOT NULL,
  embedding VECTOR(1536) NOT NULL,
  importance INT DEFAULT 5,
  memory_type TEXT CHECK (memory_type IN ('personal', 'relationship', 'preference', 'event')),
  entities JSONB,
  created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX memories_embedding_idx ON memories 
USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
```

#### 3.3 MemoryManager (1.5h):
```javascript
// api/lib/memory-manager.js
class MemoryManager {
  async createEmbedding(text)
  async saveMemory(userId, summary, importance)
  async getRelevantMemories(userId, query, limit)
  async extractEntities(text)
}
```

#### 3.4 Function Calling (1h):
```javascript
functions: [{
  name: "remember_this",
  description: "Zapisz wa≈ºne wspomnienie",
  parameters: {
    summary: { type: "string" },
    importance: { type: "number", min: 1, max: 10 }
  }
}]
```

### üìÖ FAZA 4 - Nowy Chat API z PamiƒôciƒÖ (4h):
- Pe≈Çna reimplementacja /api/chat
- Integracja z conversations
- Pobieranie relevant memories
- Streaming + function calling
- System prompt z kontekstem

#### Memory Rules (do system prompt):
```
ZASADY ZARZƒÑDZANIA PAMIƒòCIƒÑ:

1. ZAWSZE zapisuj gdy u≈ºytkownik wspomina:
   - Imiona bliskich (partner, dzieci, rodzice)
   - Wa≈ºne daty (rocznice, urodziny)
   - Traumatyczne wydarzenia
   - Preferencje komunikacyjne

2. U≈ºywaj funkcji remember_this() gdy dowiesz siƒô czego≈õ wa≈ºnego
   Przyk≈Çad: "M√≥j mƒÖ≈º Maciej..." ‚Üí remember_this("MƒÖ≈º ma na imiƒô Maciej", 9)

3. Priorytetyzuj (importance 1-10):
   - 9-10: Kluczowe relacje, traumy
   - 7-8: Wa≈ºne preferencje, hobby
   - 5-6: Codzienne fakty
   - 1-4: Mniej istotne szczeg√≥≈Çy

4. NIE zapisuj:
   - Poufnych danych (has≈Ça, numery)
   - Tymczasowych stan√≥w emocjonalnych
   - Informacji z pojedynczej k≈Ç√≥tni
```

### üìÖ FAZA 5 - UI Konwersacji (3h):
- Sidebar z listƒÖ konwersacji
- ≈Åadowanie historii
- ZarzƒÖdzanie konwersacjami
- Auto-generowanie tytu≈Ç√≥w
- Mobile responsive

### üìÖ FAZA 6 - Panel Admina (2h):
- Memory Explorer
- User memories viewer
- Prompt management
- Analytics dashboard

### üìÖ FAZA 7 - OAuth (3h):
- Google Sign-In setup
- Apple Sign-In setup
- Integracja z Supabase Auth
- UI dla social login

## üìû Kontakt & Komendy
- **Admin Panel**: https://tk2me.vercel.app/admin (has≈Ço: qwe123)
- **Testowe komendy**:
  ```bash
  npm run dev          # Vercel dev mode
  git push            # Auto-deploy via webhook
  ```

## üêõ Known Issues & Status
- ~~Auto-deploy nie dzia≈Ça≈Ç~~ ‚úÖ FIXED
- ~~JavaScript syntax errors~~ ‚úÖ FIXED  
- ~~API endpoints 500 errors~~ ‚úÖ FIXED
- ~~Limit 12 funkcji Vercel~~ ‚úÖ FIXED (usuniƒôto pliki backup)
- ~~Chat Completions wolne~~ ‚úÖ FIXED (streaming dzia≈Ça!)
- **TODO**: System konwersacji (FAZA 2)
- **TODO**: System pamiƒôci AI (FAZA 3)

## üîë Kluczowe Pliki do Edycji:
### Backend:
- `/api/chat.js` - g≈Ç√≥wny endpoint czatu (obecnie: streaming SSE)
- `/api/conversations.js` - TODO: zarzƒÖdzanie konwersacjami
- `/api/lib/memory-manager.js` - TODO: system pamiƒôci
- `/supabase-schema.sql` - schema bazy danych

### Frontend:
- `/public/index.html` - g≈Ç√≥wna aplikacja (linie 1684-1850: sendMessage)
- `/public/admin-temp.html` - panel admina bez has≈Ça

### Konfiguracja:
- Supabase: https://app.supabase.com/project/hpxzhbubvdgxdvwxmhzo
- Vercel: https://vercel.com/natalias-projects-0df16838/talk2me
- Live: https://tk2me.vercel.app

## üí° Uwagi Techniczne
- Projekt u≈ºywa ES6 modules (import/export)
- Wszystkie endpointy u≈ºywajƒÖ Supabase RLS (Row Level Security)
- Admin panel wymaga Bearer token authorization
- Chat u≈ºywa OpenAI jako primary, Groq jako fallback
- Mobile-first responsive design
- Streaming przez Server-Sent Events (SSE)
- Limit Vercel: max 12 funkcji serverless

## üé® Design & UX
- Kolor g≈Ç√≥wny: #FF69B4 (r√≥≈ºowy)
- Mobile-optimized (iOS/Android)
- PWA ready (Apple Web App capable)
- Smooth animations i transitions

---
**Ostatnia aktualizacja**: 8 stycznia 2025 22:30  
**Status**: üöÄ LIVE PRODUCTION - Aplikacja dzia≈Ça w chmurze z SUPER SZYBKIM streamingiem!

## ‚úÖ SESJA 6 - INTEGRACJA ASSISTANT API & CACHE (2025-01-07)

### üöÄ G≈Å√ìWNE OSIƒÑGNIƒòCIA:
1. **Dodanie modeli GPT-4.1** - najnowsze modele OpenAI z 1M token√≥w kontekstu!
   - GPT-4.1, GPT-4.1 mini, GPT-4.1 nano
   - GPT-4.5 Research Preview
   
2. **Naprawienie zapisywania modelu** - zmiana UPDATE na UPSERT w admin/config.js
   - Teraz model siƒô zapisuje poprawnie po od≈õwie≈ºeniu strony
   
3. **Integracja Chat Completions z Assistant API**:
   - Chat pobiera prompt z OpenAI Assistant API
   - U≈ºywa go w Chat Completions dla szybkich odpowiedzi
   
4. **Cache promptu w pamiƒôci RAM**:
   - B≈Çyskawiczne odpowiedzi (0ms dla cache)
   - Auto-refresh co 1 godzinƒô
   - Brak dodatkowych zapyta≈Ñ do bazy
   
5. **Panel admina z podglƒÖdem promptu**:
   - Wy≈õwietla do 10k znak√≥w promptu
   - Przycisk "Refresh Prompt from OpenAI"
   - Status cache z informacjƒÖ o wieku

### üîß TECHNICZNE SZCZEG√ì≈ÅY:
- **promptCache** w chat.js - obiekt w pamiƒôci serwera
- **Export/Import** - admin/config.js importuje cache z chat.js
- **Brak nowych endpoint√≥w** - wykorzystanie istniejƒÖcych (limit 12)
- **Streaming nadal dzia≈Ça** - SSE bez zmian

### üìä FLOW DZIA≈ÅANIA:
1. **Pierwszy chat po deploy** ‚Üí pobiera prompt z Assistant API (~1s)
2. **Kolejne chaty** ‚Üí u≈ºywajƒÖ cache z RAM (0ms!)
3. **Po 1 godzinie** ‚Üí automatyczne od≈õwie≈ºenie
4. **Manual refresh** ‚Üí przycisk w panelu admina

### üéØ AKTUALNY STATUS:
- ‚úÖ **Chat u≈ºywa prawdziwego promptu** z OpenAI Assistant
- ‚úÖ **Wyb√≥r modeli dzia≈Ça** - wszystkie modele OpenAI dostƒôpne
- ‚úÖ **Panel admina ulepszony** - widaƒá prompt i mo≈ºna go od≈õwie≈ºyƒá
- ‚úÖ **Zero dodatkowego delay** - cache w pamiƒôci RAM

### üìù NASTƒòPNE KROKI (FAZA 2):
- [ ] System konwersacji (tabele conversations + messages)
- [ ] pgvector + semantic memory search
- [ ] UI dla historii rozm√≥w (sidebar)
- [ ] Function calling dla zapisywania pamiƒôci

## ‚úÖ SESJA 5 - CHAT COMPLETIONS + STREAMING (2025-06-08)

### üéØ G≈Å√ìWNE OSIƒÑGNIƒòCIA:
1. **10x SZYBSZE ODPOWIEDZI**:
   - By≈Ço: Assistant API ~10-30 sekund
   - Jest: Chat Completions ~1-2 sekundy!
   
2. **STREAMING TEKSTU**:
   - Implementacja Server-Sent Events (SSE)
   - P≈Çynne wy≈õwietlanie s≈Çowo po s≈Çowie
   - Animowany kursor podczas pisania
   
3. **ZACHOWANE FUNKCJE**:
   - Historia czat√≥w dalej dzia≈Ça
   - Autoryzacja u≈ºytkownik√≥w OK
   - System prompt√≥w konfigurowalny

### üîß TECHNICZNE SZCZEG√ì≈ÅY:
- Zamiana `openai.beta.assistants` ‚Üí `openai.chat.completions`
- Streaming przez `stream: true` + chunked responses
- Frontend: `fetch` ‚Üí streaming reader z parsowaniem SSE
- Backup poprzedniej wersji w `chat-backup-assistant-api.js`

### üìä POR√ìWNANIE WYDAJNO≈öCI:
| Metoda | Czas odpowiedzi | Streaming | UX |
|--------|----------------|-----------|-----|
| Assistant API | 10-30s | ‚ùå | üò¥ |
| Chat Completions | 1-2s | ‚úÖ | üöÄ |

### üé¨ NASTƒòPNE KROKI:
- FAZA 2: System konwersacji (w toku)
- FAZA 3: pgvector + pamiƒôƒá AI
- FAZA 4-7: Pe≈Çny system jak ChatGPT

## ‚úÖ SESJA 4 - UKO≈ÉCZONA MIGRACJA CLOUD (2025-06-07)

### üéâ PRZE≈ÅOMOWE OSIƒÑGNIƒòCIE:
**Aplikacja jest teraz w pe≈Çni dzia≈ÇajƒÖca w produkcji:**
- **Live URL:** https://tk2me.vercel.app  
- **Admin Panel:** https://tk2me.vercel.app/admin (qwe123)
- **Backend:** Vercel Serverless Functions
- **Database:** Supabase PostgreSQL  
- **AI:** OpenAI Chat Completions (1-2s response!)

### üîß G≈Å√ìWNE TRANSFORMACJE:
1. **SQLite ‚Üí Supabase PostgreSQL**
2. **Express.js localhost ‚Üí Vercel Serverless**  
3. **Assistant API ‚Üí Chat Completions (10x szybsze!)**
4. **Localhost ‚Üí Cloud-native production**
5. **Hardcoded colors ‚Üí CSS Variables system**
6. **Menu prawej strony ‚Üí lewe menu (sliding)**
7. **Stary prompt ‚Üí Nowy "Jamie" (jak przyjaci√≥≈Çka)**

### üéØ CURRENT STATUS:
- ‚úÖ **Aplikacja LIVE** - dzia≈Ça w internecie
- ‚úÖ **AI Chat** - OpenAI + Groq fallback  
- ‚úÖ **Admin Panel** - konfiguracja kluczy API
- ‚úÖ **UI Naprawione** - personalizacja kolor√≥w
- ‚úÖ **Auto-deploy** - GitHub ‚Üí Vercel pipeline

### ‚ùì TODO POZOSTA≈ÅE:
- [ ] Zmieniƒá emotki na symbole czarno-bia≈Çe (niska priorytet)
- [ ] Zintegrowaƒá auth system z frontendem  
- [ ] Testy produkcyjne z prawdziwymi u≈ºytkownikami

## ‚úÖ SESJA 7 - FAZA 2: SYSTEM KONWERSACJI (2025-01-08)

### üéØ PR√ìBA IMPLEMENTACJI:
1. **Utworzono schemat bazy danych**:
   - Tabele `conversations` i `messages`
   - Automatyczna migracja z `chat_history`
   - RLS policies i indeksy
   
2. **Backend API**:
   - `/api/conversations.js` - zarzƒÖdzanie konwersacjami
   - Zaktualizowany `/api/chat.js` z obs≈ÇugƒÖ conversationId
   - Streaming nadal dzia≈Ça

3. **Nowy UI (index-v2)**:
   - Sidebar z listƒÖ konwersacji (jak ChatGPT)
   - Responsywny design
   - Niestety brakuje wielu funkcji ze starego UI

### ‚ö†Ô∏è PROBLEMY NAPOTKANE:
1. **Limit funkcji Vercel** (12 na planie Hobby):
   - Musieli≈õmy usunƒÖƒá niepotrzebne pliki
   - RozwiƒÖzane przez cleanup

2. **System autoryzacji**:
   - Mieszanka Supabase Auth i custom JWT
   - Pƒôtla logowania
   - Ostatecznie wr√≥cili≈õmy do custom JWT

3. **UI/UX**:
   - Nowy interfejs straci≈Ç wiele funkcji (menu, dark mode, etc.)
   - Przywr√≥cili≈õmy stary dzia≈ÇajƒÖcy interfejs

### üìä AKTUALNY STATUS:
- ‚úÖ Backend dla konwersacji GOTOWY (tabele, API)
- ‚úÖ System auth naprawiony (custom JWT)
- ‚úÖ Tryb go≈õcia dzia≈Ça
- ‚ùå Frontend konwersacji wycofany (zbyt du≈ºo zmian naraz)

### üìù WNIOSKI:
- System konwersacji wymaga stopniowej integracji
- Lepiej dodawaƒá funkcje do istniejƒÖcego UI ni≈º zastƒôpowaƒá ca≈Çkowicie
- Backend jest gotowy, frontend do zrobienia jutro

### üé¨ PLAN NA JUTRO (SESJA 8):
1. **Hybrydowy interfejs**:
   - Zachowaƒá stary dzia≈ÇajƒÖcy UI
   - Dodaƒá przycisk "Historia rozm√≥w"
   - Opcjonalny sidebar z konwersacjami

2. **Stopniowa integracja**:
   - Konwersacje tylko dla zalogowanych
   - Go≈õcie u≈ºywajƒÖ zwyk≈Çego czatu
   - Bez psucia istniejƒÖcych funkcji

3. **Poprawki UX**:
   - Jasne komunikaty o trybie go≈õcia
   - ≈Åatwiejsze logowanie/rejestracja

## ‚úÖ SESJA 8 - PLANOWANIE MIGRACJI NA RAILWAY (2025-01-09 23:00)

### üéØ G≈Å√ìWNE OSIƒÑGNIƒòCIA:
1. **Analiza ogranicze≈Ñ Vercel dla LangChain**:
   - Limit 50MB na funkcjƒô serverless
   - Max 1GB RAM (za ma≈Ço dla LangChain)
   - Cold starts problematyczne dla AI

2. **Wyb√≥r Railway.app jako nowej platformy**:
   - 8GB RAM dostƒôpne
   - Persistent containers (brak cold starts)
   - $5/mies start, prosty jak Vercel
   - Git push = deploy

3. **Decyzja o systemie pamiƒôci z LangChain**:
   - Personalizacja AI to kluczowa funkcjonalno≈õƒá
   - LangChain u≈Çatwi semantic search
   - Integracja z pgvector dla pamiƒôci

4. **Szczeg√≥≈Çowy plan migracji (5 etap√≥w)**:
   - ETAP 1: Express.js server setup
   - ETAP 2: Railway deployment
   - ETAP 3: System konwersacji
   - ETAP 4: LangChain + Memory
   - ETAP 5: Testing & optymalizacja

### üîß TECHNICZNE SZCZEG√ì≈ÅY:
- **Architektura docelowa**: Express.js na Railway (jeden serwer)
- **Rezygnacja z**: Architektury rozproszonej, Cloudflare CDN
- **Akceptacja**: ~180ms latencji z US-West dla prostoty
- **LangChain modules**: Tylko memory, embeddings, vectorstores

### üìä ANALIZA PLATFORM:
| Platform | Pros | Cons | Decyzja |
|----------|------|------|---------|
| Vercel Pro | Znane ≈õrodowisko | Limit RAM | ‚ùå |
| Railway | 8GB RAM, prosty | Tylko US-West | ‚úÖ |
| Fly.io | Serwery w PL | Bardziej skomplikowane | ‚ùå |
| Render | EU region | Mniej RAM | ‚ùå |

### üìã ZADANIA NA JUTRO (SESJA 9):
1. **Utworzenie struktury Express.js** (45 min)
   - server.js z wszystkimi routes
   - Konwersja Vercel functions ‚Üí Express endpoints
   - Zachowanie API compatibility

2. **Setup Railway** (30 min)
   - railway.json config
   - Environment variables
   - GitHub integration

3. **Deploy & Test** (30 min)
   - Podstawowa migracja bez LangChain
   - Weryfikacja wszystkich endpoints
   - Performance check

4. **System Konwersacji** (2h)
   - SQL migration script
   - API endpoints implementation
   - Basic UI integration

5. **LangChain Layer** (3h)
   - Memory Manager implementation
   - Semantic search setup
   - Integration z chat.js

### üé¨ PLAN WYKONANIA:
```
Dzie≈Ñ 1 (Jutro):
‚îú‚îÄ‚îÄ 09:00-10:00: Express setup
‚îú‚îÄ‚îÄ 10:00-10:30: Railway deploy
‚îú‚îÄ‚îÄ 10:30-12:30: Conversations system
‚îî‚îÄ‚îÄ 14:00-17:00: LangChain integration

Dzie≈Ñ 2:
‚îú‚îÄ‚îÄ Testing & optimization
‚îú‚îÄ‚îÄ Documentation update
‚îî‚îÄ‚îÄ Production switch
```

### üìù NOTATKI Z DYSKUSJI:
- Natalia preferuje jeden serwer (prostota)
- LangChain kluczowy dla personalizacji
- Railway mimo US lokalizacji (DX > latencja)
- Migracja stopniowa, bez psucia produkcji

### ‚ö†Ô∏è DO ZAPAMIƒòTANIA:
- **Backup Vercel** przed migracjƒÖ
- **Test ka≈ºdego etapu** osobno
- **Monitor RAM** z LangChain
- **Dokumentuj zmiany** w CHANGELOG

---
**Zako≈Ñczenie sesji**: 9 stycznia 2025, 23:00
**Developer**: Claude (AI Assistant)
**Status**: Plan gotowy, implementacja jutro

## ‚úÖ SESJA 9 - MIGRACJA NA RAILWAY + PLAN LANGCHAIN (2025-01-10)

### üéØ G≈Å√ìWNE OSIƒÑGNIƒòCIA:
1. **Sukces migracji na Railway!** üöÄ
   - Branch `railway-migration` utworzony i wdro≈ºony
   - Express.js server dzia≈Ça na https://talk2me.up.railway.app
   - Wszystkie endpointy dzia≈ÇajƒÖ (chat, auth, admin)
   - SSE streaming dzia≈Ça poprawnie

**‚ö†Ô∏è WA≈ªNE: Pracujemy teraz na branchu `railway-migration`, NIE na main!**
- Railway deployuje z brancha `railway-migration`
- Vercel nadal u≈ºywa brancha `main` jako backup
- Wszystkie zmiany robimy na `railway-migration`

2. **Minimalna refaktoryzacja**:
   - Jeden plik `server.js` importuje wszystkie handlery
   - Zero zmian w kodzie API handlers
   - Express rozumie format (req, res) z Vercel

3. **Railway config**:
   - 8GB RAM dostƒôpne (vs 1GB na Vercel)
   - Persistent container (brak cold starts)
   - Health endpoint dla monitoringu
   - Auto-deploy z GitHub

### üîß TECHNICZNE SZCZEG√ì≈ÅY MIGRACJI:
```javascript
// server.js - klucz do prostej migracji
import express from 'express';
import chatHandler from './api/chat.js';
// ... import wszystkich handler√≥w

const app = express();
app.post('/api/chat', chatHandler);
// ... mapowanie routes
```

### üìä STATUS PO MIGRACJI:
- ‚úÖ Railway deployment live na https://talk2me.up.railway.app
- ‚úÖ Chat z AI dzia≈Ça (ale "trochƒô muli") 
- ‚úÖ Vercel nadal dzia≈Ça jako backup na https://tk2me.vercel.app
- ‚è≥ Optymalizacje wstrzymane do po LangChain
- üîß **Branch `railway-migration` jest teraz g≈Ç√≥wnym branchem rozwojowym**
- üîÑ Auto-deploy z GitHub przy ka≈ºdym push na `railway-migration`

### üß† PLAN IMPLEMENTACJI LANGCHAIN + MEMORY SYSTEM:

#### FAZA 1: SETUP PGVECTOR (30 min)
```sql
-- Enable pgvector w Supabase
CREATE EXTENSION IF NOT EXISTS vector;

-- Tabela memories z embeddings
CREATE TABLE memories (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES users(id),
  conversation_id UUID REFERENCES conversations(id),
  content TEXT NOT NULL,
  summary TEXT NOT NULL,
  embedding VECTOR(1536) NOT NULL,
  importance INT DEFAULT 5,
  memory_type TEXT CHECK (memory_type IN ('personal', 'relationship', 'preference', 'event')),
  entities JSONB,
  created_at TIMESTAMP DEFAULT NOW()
);

-- Index dla similarity search
CREATE INDEX memories_embedding_idx ON memories 
USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
```

#### FAZA 2: LANGCHAIN SETUP (45 min)
```javascript
// lib/memory-manager.js
import { SupabaseVectorStore } from 'langchain/vectorstores/supabase';
import { OpenAIEmbeddings } from 'langchain/embeddings/openai';

class MemoryManager {
  async initialize() {
    this.embeddings = new OpenAIEmbeddings();
    this.vectorStore = new SupabaseVectorStore(this.embeddings, {
      client: supabase,
      tableName: 'memories',
      queryName: 'match_memories'
    });
  }

  async saveMemory(userId, content, importance = 5) {
    // Create embedding & save to vector store
  }

  async getRelevantMemories(userId, query, limit = 5) {
    // Similarity search in vector store
  }
}
```

#### FAZA 3: FUNCTION CALLING (30 min)
```javascript
// Funkcja do zapamiƒôtywania wa≈ºnych informacji
const functions = [{
  name: "remember_this",
  description: "Zapisz wa≈ºne informacje o u≈ºytkowniku",
  parameters: {
    type: "object",
    properties: {
      summary: { 
        type: "string", 
        description: "Kr√≥tkie podsumowanie do zapamiƒôtania" 
      },
      importance: { 
        type: "number", 
        minimum: 1, 
        maximum: 10 
      },
      type: { 
        type: "string", 
        enum: ["personal", "relationship", "preference", "event"] 
      }
    },
    required: ["summary", "importance"]
  }
}];
```

#### FAZA 4: INTEGRACJA Z CHATEM (1h)
- Pobieranie relevant memories przed odpowiedziƒÖ
- Dodawanie kontekstu do system prompt
- Obs≈Çuga function calls (remember_this)
- Streaming z function calling

#### FAZA 5: MEMORY RULES (30 min)
```
ZASADY ZAPAMIƒòTYWANIA:

1. ZAWSZE zapisuj gdy dowiadujesz siƒô:
   - Imion bliskich (partner, dzieci, rodzice)
   - Wa≈ºnych dat (rocznice, urodziny)
   - Traumatycznych wydarze≈Ñ
   - Preferencji komunikacyjnych

2. Priorytetyzacja (1-10):
   - 9-10: Kluczowe relacje, traumy
   - 7-8: Wa≈ºne preferencje
   - 5-6: Codzienne fakty
   
3. NIE zapisuj:
   - Danych poufnych (has≈Ça, numery kart)
   - Chwilowych stan√≥w emocjonalnych
```

#### FAZA 6: TESTING (30 min)
- Test zapisywania r√≥≈ºnych typ√≥w pamiƒôci
- Test similarity search
- Test personalizacji odpowiedzi
- Performance z LangChain

### üì¶ NOWE DEPENDENCIES:
```json
{
  "langchain": "^0.1.0",
  "@langchain/openai": "^0.0.10",
  "@langchain/community": "^0.0.10",
  "pgvector": "^0.1.0"
}
```

### üéØ EFEKT KO≈ÉCOWY:
- **AI pamiƒôta u≈ºytkownika** miƒôdzy sesjami
- **Personalizowane odpowiedzi** bazujƒÖce na historii
- **Automatyczne wy≈Çapywanie** wa≈ºnych informacji
- **Kontekst relacji** w ka≈ºdej rozmowie

### ‚ö†Ô∏è WA≈ªNE DECYZJE:
- **Optymalizacje p√≥≈∫niej** - najpierw funkcjonalno≈õci
- **Nie u≈ºywaƒá PM2 cluster** - konflikt z LangChain memory
- **Railway ma do≈õƒá RAM** - 8GB powinno wystarczyƒá

### üìù NEXT STEPS:
1. Implementacja pgvector schema
2. MemoryManager class
3. Integracja z chat.js
4. Testy z prawdziwymi u≈ºytkownikami

---
**Status sesji**: Railway dzia≈Ça, plan LangChain gotowy
**Do zrobienia**: Implementacja memory system po powrocie ze spaceru
**Branch**: `railway-migration` (NIE main!)
**Deploy**: Railway auto-deploy z brancha `railway-migration`